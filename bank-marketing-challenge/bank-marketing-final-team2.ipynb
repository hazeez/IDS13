{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.features import rank2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_enable = True\n",
    "cv = 2\n",
    "verbose = 3\n",
    "number_of_jobs = -1\n",
    "rand_state = 101\n",
    "test_size = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf = pd.read_csv(\"featured_bank_imputed_wo_duration_year.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def festivals(month):\n",
    "    # imputing festivals - apr: easter; jun:carnival; dec:christmas\n",
    "    if month == 'apr' or month == 'jun' or month == 'dec':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.festivals'] = bdf['month'].apply(festivals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bonus_months(month):\n",
    "    # bonus paid twice in a year - may and nov\n",
    "    if month == 'jun' or month == 'dec':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.bonus_months']= bdf['month'].apply(bonus_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commitment(housing, personal, marital):\n",
    "    # if a person is married and has housing and personal loans, flag it as high commitment\n",
    "    if housing == 'yes' and personal == 'yes' and marital == 'married':\n",
    "        return 'high'\n",
    "    if housing == 'no' and personal == 'no' and marital in ['single']:\n",
    "        return 'low'\n",
    "    else:\n",
    "        return 'medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.commitment'] = bdf.apply(lambda x: commitment(x.housing, x.loan, x.marital), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasons(month):\n",
    "    if month in ['mar','apr','may']:\n",
    "        return 'spring'\n",
    "    if month in ['jun','jul','aug']:\n",
    "        return 'summer'\n",
    "    if month in ['sep','oct','nov']:\n",
    "        return 'autumn'\n",
    "    if month in ['dec','jan','feb']:\n",
    "        return 'winter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.seasons'] = bdf['month'].apply(lambda mon: seasons(mon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasons_weightage(season):\n",
    "    if season == 'autumn':\n",
    "        return 21\n",
    "    if season == 'spring':\n",
    "        return 36\n",
    "    if season == 'summer':\n",
    "        return 40\n",
    "    if season == \"winter\":\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bdf ['f.season_weight'] = bdf['f.seasons'].apply(lambda season: seasons_weightage(season))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retired(age):\n",
    "    if age >= 65:\n",
    "        return 'retired'\n",
    "    else:\n",
    "        return 'not-retired'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.retired_status'] = bdf['age'].apply(lambda age: retired(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marital_weightage(marital):\n",
    "    if marital == 'divorced':\n",
    "        return 1\n",
    "    if marital == 'single':\n",
    "        return 35\n",
    "    if marital == 'married':\n",
    "        return 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bdf['f.marital_weightage'] = bdf['marital'].apply(lambda status: marital_weightage(status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_weightage(age):\n",
    "    if age == '11_to_20':\n",
    "        return 0.01\n",
    "    if age == '21_to_30':\n",
    "        return 0.23\n",
    "    if age == '31_to_40':\n",
    "        return 0.34\n",
    "    if age == '41_to_50':\n",
    "        return 0.18\n",
    "    if age == '51_to_60':\n",
    "        return 0.14\n",
    "    if age == '61_to_70':\n",
    "        return 0.04\n",
    "    if age == '71_to_80':\n",
    "        return 0.03\n",
    "    if age == '81_to_90':\n",
    "        return 0.01\n",
    "    if age == '91_to_100':\n",
    "        return 0.00\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bdf['f.age_weightage'] = bdf['f.age'].apply(lambda age: age_weightage(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previous_user(previous):\n",
    "    if previous == 0:\n",
    "        return 'new user'\n",
    "    else:\n",
    "        return 'existing user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.user_type'] = bdf['previous'].apply(lambda previous: previous_user(previous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previous_no_of_times(previous):\n",
    "    # if a user is part of the previous campaign, bin them\n",
    "    if previous == 0:\n",
    "        return 'no previous'\n",
    "    if previous >= 1 and previous <= 3:\n",
    "        return '1_to_3'\n",
    "    if previous > 3:\n",
    "        return 'gt_3'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.previous_campaigns'] = bdf['previous'].apply(lambda previous: previous_no_of_times(previous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_campaign_calls(calls):\n",
    "    # how many times a user is called\n",
    "    if calls == 1:\n",
    "        return 'once'\n",
    "    if calls >= 2 and calls <= 3:\n",
    "        return 'twice to thrice '\n",
    "    if calls > 3 and calls <= 6:\n",
    "        return 'four to six times'\n",
    "    if calls >= 7 and calls <= 10:\n",
    "        return 'seven to ten times'\n",
    "    if calls > 10:\n",
    "        return 'more than ten times'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.current_campaign_calls'] = bdf['campaign'].apply(lambda calls: current_campaign_calls(calls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_time_user_calls(previous, campaigns):\n",
    "    # first time user - not a part of previous campaign\n",
    "    # first time the user is speaking - what's the conversion rate\n",
    "    if previous == 0:\n",
    "        if campaigns == 1:\n",
    "            return 'first time called'\n",
    "        if campaigns >= 2 and campaigns <= 3:\n",
    "            return 'called atleast twice'\n",
    "        if campaigns > 3:\n",
    "            return 'called atleast thrice'\n",
    "        else:\n",
    "            return 'more than thrice'\n",
    "    else:\n",
    "        return 'returning user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.first_time_user_calls'] = bdf.apply(lambda x: first_time_user_calls(x.previous, x.campaign), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savings_intention(job):\n",
    "    if job in ['admin.','blue-collar','technician']:\n",
    "        return 100\n",
    "    elif job in ['retired','management','services']:\n",
    "        return 50\n",
    "    else:\n",
    "        return 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.savings_intent_factor'] = bdf['job'].apply(lambda job: savings_intention(job))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_range_weightage(age):\n",
    "    if age <= 24:\n",
    "        return 0.15\n",
    "    if age >=25 and age <= 69:\n",
    "        return 0.61\n",
    "    if age >= 70 and age <= 80:\n",
    "        return 0.13\n",
    "    if age > 80:\n",
    "        return 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.age_range_weightage'] = bdf['age'].apply(lambda age: age_range_weightage(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_income_distribution(salary, marital):\n",
    "    if marital == 'married':\n",
    "        return round((salary/3),2)\n",
    "    if marital == 'single':\n",
    "        return salary\n",
    "    if marital == 'divorced':\n",
    "        return round((salary/2),2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bdf['f.avg_income_dist'] = bdf.apply(lambda x: avg_income_distribution(x['f.salary'], x['marital']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_days_bin(pdays):\n",
    "    if pdays >=0 and pdays <=6:\n",
    "        return 'within a week'\n",
    "    if pdays >=7 and pdays <=13:\n",
    "        return 'within two weeks'\n",
    "    if pdays >= 14 and pdays <=20:\n",
    "        return 'within three weeks'\n",
    "    if pdays > 20:\n",
    "        return 'more than three weeks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.pdays'] = bdf['pdays'].apply(lambda days: p_days_bin(days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_weightage(year):\n",
    "    if year == \"Y2008\":\n",
    "        return 5\n",
    "    if year == \"Y2009\":\n",
    "        return 14\n",
    "    if year == \"Y2010\":\n",
    "        return 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bdf['f.year_weightage'] = bdf['f.year'].apply(lambda year: year_weightage(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recession_strength(year, month):\n",
    "    if year == \"Y2008\":\n",
    "        if month in ['mar','apr','may','jun','jul','aug','sep','oct','nov','dec']:\n",
    "            return 'peak'\n",
    "    elif year == \"Y2009\":\n",
    "        if month in ['mar','apr','may']:\n",
    "            return 'peak'\n",
    "        else:\n",
    "            return 'non-peak'\n",
    "    else:\n",
    "        return 'non-peak'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.recession_strength'] = bdf.apply(lambda x: recession_strength(x['f.year'],x['month']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be removed\n",
    "def week_breakup(day):\n",
    "    if day == \"mon\":\n",
    "        return 'week_start'\n",
    "    if day in ['tue','wed','thu']:\n",
    "        return 'week_mid'\n",
    "    if day in ['fri']:\n",
    "        return 'week_end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.week_breakup'] = bdf['day_of_week'].apply(week_breakup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be removed\n",
    "def week_day_weightage(weekday):\n",
    "    if weekday == 'week_start':\n",
    "        return 14\n",
    "    if weekday == 'week_mid':\n",
    "        return 38\n",
    "    if weekday == 'week_end':\n",
    "        return 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bdf['f.week_day_weightage'] = bdf['f.week_breakup'].apply(week_day_weightage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emp_rate_change(rate):\n",
    "    if rate > 0:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.emp_var_rate'] = bdf['emp.var.rate'].apply(emp_rate_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cons_price_bin(index):\n",
    "\tif index >=92 and index <=92.5:\n",
    "\t\treturn 'gt_92_lt_92.5'\n",
    "\tif index >92.5 and index <= 93:\n",
    "\t\treturn 'gt_925_lt_93'\n",
    "\tif index >93 and index <= 93.5:\n",
    "\t\treturn 'gt_93_lt_935'\n",
    "\tif index >93.5 and index <= 94:\n",
    "\t\treturn 'gt_935_lt_94'\n",
    "\tif index >94 and index <= 94.5:\n",
    "\t\treturn 'gt_94_lt_94.5'\n",
    "\tif index >94.5 and index <= 95:\n",
    "\t\treturn 'gt_945_lt_95'\n",
    "\tif index <92:\n",
    "\t\treturn 'lt_92'\n",
    "\tif index >95:\n",
    "\t\treturn 'gt_95'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.cons.price.bin'] = bdf['cons.price.idx'].apply(cons_price_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emp_var_bin(index):\n",
    "\tif index < -3.5:\n",
    "\t\treturn 'lt_min_3.5'\n",
    "\tif index >= -3.5 and index <= -3:\n",
    "\t\treturn 'gt_min_35_lt_3'\n",
    "\tif index > -3 and index <= -2.5:\n",
    "\t\treturn 'gt_min_3_lt_25'\n",
    "\tif index >-25 and index <= -2:\n",
    "\t\treturn 'gt_min_25_lt_2'\n",
    "\tif index >-2 and index <= -1.5:\n",
    "\t\treturn 'gt_min_2_lt_15'\n",
    "\tif index >-1.5 and index <= -1:\n",
    "\t\treturn 'gt_min_15_lt_1'\n",
    "\tif index >-1 and index <= -0.5:\n",
    "\t\treturn 'gt_min_1_lt_point5'\n",
    "\tif index >-0.5 and index <= 0:\n",
    "\t\treturn 'gt_min_05_lt_0'\n",
    "\tif index >0 and index <= 0.5:\n",
    "\t\treturn 'gt_0_lt_05'\n",
    "\tif index >0.5 and index <= 1:\n",
    "\t\treturn 'gt_05_lt_05'\n",
    "\tif index > 1:\n",
    "\t\treturn 'gt_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.emp.var.bin'] = bdf['emp.var.rate'].apply(emp_var_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cons_conf_bin(index):\n",
    "\tif index < -51:\n",
    "\t\treturn 'lt_51'\n",
    "\tif index >= -51 and index <= -46:\n",
    "\t\treturn 'gt_51_lt_46'\n",
    "\tif index > -46 and index <= -41:\n",
    "\t\treturn 'gt_46_lt_41'\n",
    "\tif index > -41 and index <= -36:\n",
    "\t\treturn 'gt_41_lt_36'\n",
    "\tif index > -36 and index <= -31:\n",
    "\t\treturn 'gt_36_lt_31'\n",
    "\tif index > -31 and index <= -26:\n",
    "\t\treturn 'gt_31_lt_26'\n",
    "\tif index > -26:\n",
    "\t\treturn 'gt_26'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.cons.conf.bin'] = bdf['cons.conf.idx'].apply(cons_conf_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_prob_user_job(user_type, job):\n",
    "    if user_type == \"existing user\":\n",
    "        if job in ['admin.','housemaid','management','retired','student','technician','unemployed']:\n",
    "            return 'high'\n",
    "        else:\n",
    "            return 'low'\n",
    "    else:\n",
    "        return 'low'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bdf['f.userjob_buy.prob'] = bdf.apply(lambda x: buy_prob_user_job(x['f.user_type'], x['job']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salaried_or_not(job):\n",
    "    if job in ['admin.','blue-collar', 'housemaid','management','services','retired','technician']:\n",
    "        return 'salaried'\n",
    "    else:\n",
    "        return 'not salaried'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.sal_or_not'] = bdf['job'].apply(salaried_or_not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarter(month):\n",
    "    if month in ['apr','may','jun']:\n",
    "        return 'Q1'\n",
    "    if month in ['jul','aug','sep']:\n",
    "        return 'Q2'\n",
    "    if month in ['oct','nov','dec']:\n",
    "        return 'Q3'\n",
    "    if month in ['jan','feb','mar']:\n",
    "        return 'Q4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.quarter'] = bdf['month'].apply(quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def into_loans(housing, personal):\n",
    "    if housing == 'no' and personal == \"no\":\n",
    "        return 'not_into_loans'\n",
    "    else:\n",
    "        return 'into_loans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.into_loans'] = bdf.apply(lambda x: into_loans(x.housing, x.loan), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sal = {\n",
    "    'housemaid' : 500,\n",
    "    'services' : 700,\n",
    "    'admin.' : 600,\n",
    "    'blue-collar' : 500,\n",
    "    'technician' : 600,\n",
    "    'retired' : 500,\n",
    "    'management' : 1600,\n",
    "    'unemployed' : 400,\n",
    "    'self-employed' : 800,\n",
    "    'entrepreneur' : 1200,\n",
    "    'student' : 400\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_sal = {\n",
    "    'basic.4y' : 1,\n",
    "    'high.school' : 1.6,\n",
    "    'basic.6y' : 1.2,\n",
    "    'basic.9y' : 1.4,\n",
    "    'professional.course' : 1.6,\n",
    "    'university.degree' : 2,\n",
    "    'illiterate' : 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary_job_education(job, education):\n",
    "    job_base_sal = base_sal[job]\n",
    "    edu_factor = edu_sal[education]\n",
    "    if job in ['retired','unemployed','self-employed','entrepreneur']:\n",
    "        sal = job_base_sal * edu_factor * 12\n",
    "    else:\n",
    "        sal = job_base_sal * edu_factor * 14\n",
    "    return sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.income'] = bdf.apply(lambda x: salary_job_education(x.job, x.education), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def income_tax(salary):\n",
    "    if salary >=0 and salary <=7112:\n",
    "        return 14.5\n",
    "    if salary >=7113 and salary <=10732:\n",
    "        return 23\n",
    "    if salary >=10733 and salary <=20322:\n",
    "        return 28.5\n",
    "    if salary >=20323 and salary <=25075:\n",
    "        return 35\n",
    "    if salary >=25076 and salary <=36967:\n",
    "        return 37\n",
    "    if salary >=36968:\n",
    "        return 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.income_tax'] = bdf['f.income'].apply(lambda salary: income_tax(salary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def econ_status(income):\n",
    "    if income <= 7800:\n",
    "        return 'lower class'\n",
    "    if income >7800 and income <= 26400:\n",
    "        return 'middle class'\n",
    "    if income > 26400:\n",
    "        return 'upper class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.econ_status'] = bdf['f.income'].apply(econ_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_prob_status_marital(marital_status):\n",
    "    if marital_status in ['married','single']:\n",
    "        return 'high'\n",
    "    else:\n",
    "        return 'low'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.user.buy.prob'] = bdf['marital'].apply(buy_prob_status_marital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bailout_period(year):\n",
    "    if year == \"Y2010\":\n",
    "        return \"bailout\"\n",
    "    else:\n",
    "        return \"non-bailout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bdf['f.bailout_status'] = bdf['f.year'].apply(bailout_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def education_level(education):\n",
    "    if education in ['illiterate','basic.4y','basic.6y']:\n",
    "        return 'low-education'\n",
    "    if education in ['basic.9y','high.school']:\n",
    "        return 'medium-education'\n",
    "    if education in ['professional.course','university.degree']:\n",
    "        return 'high-education'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.education'] = bdf['education'].apply(education_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_to_retirement(age):\n",
    "    if age < 65:\n",
    "        return 65 - age\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.age_to_retire'] = bdf['age'].apply(age_to_retirement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_range_to_retire(diff_age):\n",
    "    if diff_age == 0:\n",
    "        return 0\n",
    "    if diff_age >=1 and diff_age <=5:\n",
    "        return 0.3\n",
    "    if diff_age >=6 and diff_age <=35:\n",
    "        return 0.1\n",
    "    if diff_age >= 36 and diff_age <= 40:\n",
    "        return 0.14\n",
    "    if diff_age >= 41 and diff_age <= 45:\n",
    "        return 0.22\n",
    "    if diff_age >= 46:\n",
    "        return 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.age_to_retire_weight'] = bdf['f.age_to_retire'].apply(age_range_to_retire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_to_eol(age):\n",
    "    if age < 80:\n",
    "        return 80 - age\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.age_to_death'] = bdf['age'].apply(age_to_eol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_range_to_death(diff_age):\n",
    "    if diff_age >=0 and diff_age <= 19:\n",
    "        return '0_to_19'\n",
    "    if diff_age >=20 and diff_age <= 39:\n",
    "        return '20_to_39'\n",
    "    if diff_age >=40 and diff_age <=59:\n",
    "        return '40_to_59'\n",
    "    if diff_age >=60:\n",
    "        return '60_to_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.remaining_age'] = bdf['f.age_to_death'].apply(age_range_to_death)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unemployment_rate(recession_strength, age_range, salaried):\n",
    "    if recession_strength == \"peak\":\n",
    "        if age_range in ['21_to_30','31_to_40']:\n",
    "            return -30\n",
    "        else:\n",
    "            return -8\n",
    "    else:\n",
    "        return -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['f.unemployment'] = bdf.apply(lambda x: unemployment_rate(x['f.recession_strength'],x['f.age'],x['f.sal_or_not']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf.to_csv('testv4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_columns= ['s.no', 'age','nr.employed','default','pdays', 'emp.var.rate',\n",
    "                  'campaign','cons.price.idx','cons.conf.idx', 'f.quarter','f.income_tax','f.age_to_death',\n",
    "                  'f.age_to_retire',\n",
    "                 ]\n",
    "categorical_columns=['job','marital','housing','loan','education','contact','month','day_of_week',\n",
    "                     'poutcome','f.euribor1','f.age', 'f.commitment','f.week_breakup',\n",
    "                    'f.seasons','f.retired_status', 'f.user_type', 'f.pattern',\n",
    "                     'f.previous_campaigns','f.current_campaign_calls','f.first_time_user_calls', \n",
    "                     'f.pdays', 'f.emp_var_rate','f.year','f.cons.price.bin',\n",
    "                     'f.emp.var.bin','f.cons.conf.bin','f.recession_strength',\n",
    "                     'f.econ_status','f.sal_or_not','f.into_loans','f.remaining_age','f.education',\n",
    "                     'f.user.buy.prob',\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns\n",
    "bdf.drop(dropped_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert columns of object type to categorical columns\n",
    "bdf_cat = bdf[categorical_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf[categorical_columns] = bdf[categorical_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop bdf categorical columns from the dataframe\n",
    "bdf_noncat = bdf.drop(categorical_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf_noncat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use one hot encoding for categorical columns\n",
    "bdf_cat_one_hot = pd.get_dummies(bdf_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf_cat_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat categorical df with non categorical df\n",
    "bdf_master = pd.concat([bdf_noncat, bdf_cat_one_hot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store only the target variable column\n",
    "y = bdf_master.pop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the target variable column from the master dataset\n",
    "X = bdf_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the propotion of yes and no looks the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_classification_rpt(model):\n",
    "    visualizer = ClassificationReport(model, classes=['no','yes'], cmap=\"YlGn\", size=(600,300))\n",
    "    visualizer.fit(X_train, y_train)\n",
    "    visualizer.score(X_test, y_test)\n",
    "    visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that fits and predicts\n",
    "def fit_predict(algo,X_train, X_test, y_train, y_test):\n",
    "    algo.fit(X_train, y_train)\n",
    "    y_pred = algo.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy with Logistic Regression\", end=': ')\n",
    "y_pred_logit = fit_predict(logit, X_train, X_test, y_train, y_test)\n",
    "logit_accuracy = accuracy_score(y_test, y_pred_logit)\n",
    "print(logit_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classification_rpt(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,y_pred_logit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy with Decision Tree\", end=': ')\n",
    "y_pred_tree = fit_predict(tree, X_train, X_test, y_train, y_test)\n",
    "tree_accuracy = accuracy_score(y_test, y_pred_tree)\n",
    "print(tree_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classification_rpt(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_dt(train, test, y_train, y_test, scaler, max_depth,\n",
    "               criterion = 'entropy', max_features=1, min_samples_split=4):\n",
    "    train_scaled = scaler.fit_transform(train)\n",
    "    test_scaled = scaler.transform(test)\n",
    "    dt = DecisionTreeClassifier(criterion = criterion, max_depth=max_depth,\n",
    "                               random_state= 101, max_features=max_features,\n",
    "                               min_samples_split=min_samples_split)\n",
    "    dt.fit(train_scaled, y_train)\n",
    "    y_pred = dt.predict(test_scaled)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max depth parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_max_depth = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,30):\n",
    "    print(\"Accuracy score using max_depth = \", i, end = ':')\n",
    "    y_pred_tree_hpt = fit_predict_dt(X_train, X_test, y_train, y_test, StandardScaler(), i)\n",
    "    dt_max_depth = accuracy_score(y_test, y_pred_tree_hpt)\n",
    "    print(dt_max_depth)\n",
    "    list_max_depth.append(dt_max_depth)\n",
    "    \n",
    "max_depth_tuned = list_max_depth.index(max(list_max_depth))+1\n",
    "print(max_depth_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max features tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_max_features = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0.1,1.0,0.1):\n",
    "    print('Accuracy score using max features =', i, end = \":\")\n",
    "    y_pred_max_features = fit_predict_dt(X_train, X_test, y_train, y_test, StandardScaler(), max_depth=max_depth_tuned, max_features=i)\n",
    "    dt_max_features = accuracy_score(y_test, y_pred_max_features)\n",
    "    print(dt_max_features)\n",
    "    dict_max_features[i]=dt_max_features\n",
    "\n",
    "max_feature_tuned = max(dict_max_features, key=dict_max_features.get)\n",
    "print(max_feature_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min samples split tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_min_samples_split = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,10):\n",
    "    print('Accuracy score using min samples split=', i, end=\":\")\n",
    "    y_pred_min_split = fit_predict_dt(X_train, X_test, y_train, y_test, StandardScaler(), max_depth=max_depth_tuned, max_features=max_feature_tuned, min_samples_split=i)\n",
    "    dt_min_sample_split = accuracy_score(y_test, y_pred_min_split)\n",
    "    print(dt_min_sample_split)\n",
    "    dict_min_samples_split[i] = dt_min_sample_split\n",
    "    \n",
    "min_sample_split_tuned = max(dict_min_samples_split, key=dict_min_samples_split.get)\n",
    "print(min_sample_split_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_index_tuned = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['gini','entropy']:\n",
    "    print(\"Accuracy score using criterion: \", i, end = ':')\n",
    "    y_pred_index_score = fit_predict_dt(X_train, X_test, y_train, y_test, StandardScaler(), max_depth=max_depth_tuned, max_features = max_feature_tuned, min_samples_split=min_sample_split_tuned, criterion= i)\n",
    "    dt_index_score = accuracy_score(y_test, y_pred_index_score)\n",
    "    print(dt_index_score)\n",
    "    dict_index_tuned[i] = dt_index_score\n",
    "\n",
    "dt_index_tuned = max(dict_index_tuned, key=dict_index_tuned.get)\n",
    "print(dt_index_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rerunning decision tree with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_best_pred  =  fit_predict_dt(X_train, X_test, y_train, y_test, StandardScaler(), max_depth=max_depth_tuned, max_features = max_feature_tuned, min_samples_split=min_sample_split_tuned, criterion= dt_index_tuned)\n",
    "dt_best_param_score = accuracy_score(y_test, tree_best_pred)\n",
    "print(\"Accuracy score for decision tree using best param: \", end = ':')\n",
    "print(dt_best_param_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = DecisionTreeClassifier(criterion = dt_index_tuned, max_depth=max_depth_tuned,\n",
    "                               random_state= rand_state, max_features=max_feature_tuned,\n",
    "                               min_samples_split=min_sample_split_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classification_rpt(tree1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, tree_best_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_poly(train, test, degree):\n",
    "    poly = PolynomialFeatures(degree = degree)\n",
    "    train_poly = poly.fit_transform(train)\n",
    "    test_poly = poly.fit_transform(test)\n",
    "    return train_poly, test_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## polynomial features taking a lot of time as the number of columns are more. Hence commented the following piece of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for degree in [1,2,3,4]:\n",
    "#     train_poly, test_poly = create_poly(X_train, X_test, degree)\n",
    "#     print(\"polynomial degree\", degree)\n",
    "#     fit_predict(train_poly, test_poly, y_train, y_test, StandardScaler(), 16, max_features = 0.2,min_samples_split=4, criterion='entropy')\n",
    "#     print(10 *'-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(criterion='entropy', oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy with Random Forest\", end=': ')\n",
    "rf_pred = fit_predict(forest, X_train, X_test, y_train, y_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(rf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classification_rpt(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [200,500,700],\n",
    "    'max_depth': [10,15,20,25],\n",
    "    'min_samples_leaf': [3,5,7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(forest, params, cv=cv, verbose=verbose, n_jobs=number_of_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    forest_best_max_depth = gs.best_params_['max_depth']\n",
    "    forest_best_min_samples = gs.best_params_['min_samples_leaf']\n",
    "    forest_best_n_estimators = gs.best_params_['n_estimators']\n",
    "    #forest_best_criterion = gs.best_params_['criterion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining with best estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    forest1 = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='entropy', max_depth=forest_best_max_depth, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=forest_best_min_samples, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=forest_best_n_estimators,\n",
    "                       n_jobs=number_of_jobs, oob_score=True, random_state=rand_state,\n",
    "                       verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    forest1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    pred_forest1 = forest1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    print(\"Accuracy with Random Forest after Hyper Parameter Tuning\", end=': ')\n",
    "    rf_hyper_accuracy = accuracy_score(y_test, pred_forest1)\n",
    "    print(rf_hyper_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    for x in sorted(list(zip(forest1.feature_importances_, X_train.columns)), reverse=True):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    show_classification_rpt(forest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, pred_forest1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Summary Without Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy with Logistic Regression\", end=': ')\n",
    "print(logit_accuracy)\n",
    "print(\"Accuracy with Decision Tree\", end=': ')\n",
    "print(tree_accuracy)\n",
    "print(\"Accuracy of Decision Tree after Hyper Parameter Tuning: \", end = ':')\n",
    "print(dt_best_param_score)\n",
    "print(\"Accuracy with Random Forest\", end=': ')\n",
    "print(rf_accuracy)\n",
    "if grid_search_enable == True:\n",
    "    print(\"Accuracy with Random Forest after Hyper Parameter Tuning\", end=': ')\n",
    "    print(rf_hyper_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adabst_fit = AdaBoostClassifier(base_estimator=logit, random_state=rand_state, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adabst_fit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy with Ada Boost\", end=': ')\n",
    "ada_boost_predict = adabst_fit.predict(X_test)\n",
    "ada_boost_accuracy = accuracy_score(y_test,ada_boost_predict)\n",
    "print(ada_boost_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classification_rpt(adabst_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, ada_boost_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_adaboost = {\n",
    "    'n_estimators': [100,200,300],\n",
    "    'base_estimator': [logit, tree1],\n",
    "    'learning_rate': [0.5,0.75,1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_gs = GridSearchCV(adabst_fit, params_adaboost, cv=cv, n_jobs=number_of_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    ada_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    adabst_best_estimator = ada_gs.best_params_['base_estimator']\n",
    "    adabst_best_learning_rate = ada_gs.best_params_['learning_rate']\n",
    "    adabst_best_n_estimators = ada_gs.best_params_['n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    ada_gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost - Retraining with best estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    ada_best = AdaBoostClassifier(base_estimator=adabst_best_estimator, random_state=rand_state,\n",
    "                                  n_estimators=adabst_best_n_estimators, learning_rate=adabst_best_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    ada_best.fit(X_train, y_train)\n",
    "    ada_best_predict = ada_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    print(\"Accuracy with Adaboost after Hyper Parameter Tuning\", end=': ')\n",
    "    ada_best_hyper_accuracy = accuracy_score(y_test, ada_best_predict)\n",
    "    print(ada_best_hyper_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    show_classification_rpt(ada_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, ada_best_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_fit = GradientBoostingClassifier(n_estimators=500,\n",
    "                                     min_samples_split=2,min_samples_leaf=1,max_depth=1,random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_fit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy with Gradient Boost\", end=': ')\n",
    "y_pred_gbc = gbc_fit.predict(X_test)\n",
    "gbc_accuracy = accuracy_score(y_test, y_pred_gbc)\n",
    "print(gbc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classification_rpt(gbc_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_gbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boost with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_gbc = {\n",
    "    'n_estimators': [100,300,500],\n",
    "    'max_depth': [2,3,4],\n",
    "    'learning_rate': [0.05,0.075,0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_gs = GridSearchCV(gbc_fit, params_gbc, cv=cv, n_jobs=number_of_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    gbc_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    gbc_best_estimator = gbc_gs.best_params_['n_estimators']\n",
    "    gbc_best_max_depth = gbc_gs.best_params_['max_depth']\n",
    "    gbc_best_learning_rate = gbc_gs.best_params_['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    print(gbc_gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost - With Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    gbc_best = GradientBoostingClassifier(n_estimators=gbc_best_estimator,\n",
    "                                     min_samples_split=2,min_samples_leaf=1,max_depth=gbc_best_max_depth,random_state=rand_state,\n",
    "                                         learning_rate=gbc_best_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    gbc_best.fit(X_train, y_train)\n",
    "    gbc_best_predict = gbc_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    print(\"Accuracy with Gradient Boost after Hyper Parameter Tuning\", end=': ')\n",
    "    gbc_best_hyper_accuracy = accuracy_score(y_test, gbc_best_predict)\n",
    "    print(gbc_best_hyper_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    show_classification_rpt(gbc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, gbc_best_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM = LGBMClassifier(n_jobs=number_of_jobs, num_leaves=31)\n",
    "LGBM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM_predict = LGBM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy with LGBM\", end=': ')\n",
    "lgbm_accuracy = accuracy_score(y_test,LGBM_predict)\n",
    "print(lgbm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classification_rpt(LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, LGBM_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM With Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'num_leaves': [31,35,41,45],\n",
    "    'n_estimators': [50,75,100,150]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    lgbm_gs = GridSearchCV(LGBM, lgbm_params, cv=cv, n_jobs=number_of_jobs)\n",
    "    lgbm_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    lgbm_best_estimator = lgbm_gs.best_params_['n_estimators']\n",
    "    lgbm_best_num_leaves = lgbm_gs.best_params_['num_leaves']\n",
    "    print(lgbm_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    show_classification_rpt(lgbm_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM With Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    LGBM_best = LGBMClassifier(n_jobs=number_of_jobs, num_leaves=lgbm_best_num_leaves, \n",
    "                               n_estimators=lgbm_best_estimator)\n",
    "    LGBM_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    LGBM_best_predict = LGBM_best.predict(X_test)\n",
    "    LGBM_accuracy_score = accuracy_score(y_test,LGBM_best_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    print(\"Accuracy with LGBM with Hyper Parameter Tuning\", end=': ')\n",
    "    print(LGBM_accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    show_classification_rpt(LGBM_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, LGBM_best_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_fit = XGBClassifier(max_depth=2, n_estimators=5000, random_state=rand_state, n_jobs=number_of_jobs)\n",
    "xgb_fit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy with XG Boost\", end=': ')\n",
    "xgb_predict = xgb_fit.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test,xgb_predict)\n",
    "print(xgb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classification_rpt(xgb_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'max_depth': [2,3,4],\n",
    "    'n_estimators': [300,500,700],\n",
    "    'learning_rate': [0.05,0.075,0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gs = GridSearchCV(xgb_fit, xgb_params, cv=cv, n_jobs=number_of_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    xgb_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    print(xgb_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    xgb_best_max_depth = xgb_gs.best_params_['max_depth']\n",
    "    xgb_best_n_estimators = xgb_gs.best_params_['n_estimators']\n",
    "    xgb_best_learning_rate = xgb_gs.best_params_['learning_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-running XG Boost with Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    xgb_best = XGBClassifier(max_depth=xgb_best_max_depth,\n",
    "                             n_estimators=xgb_best_n_estimators, random_state=rand_state,\n",
    "                             n_jobs=number_of_jobs, learning_rate = xgb_best_learning_rate)\n",
    "    xgb_best.fit(X_train, y_train)\n",
    "    xgb_best_predict = xgb_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    print(\"Accuracy with XG Boost after Hyper Parameter Tuning\", end=': ')\n",
    "    xgb_best_hyper_accuracy = accuracy_score(y_test, xgb_best_predict)\n",
    "    print(xgb_best_hyper_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    show_classification_rpt(xgb_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search_enable == True:\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, xgb_best_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Summary With Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy with Logistic Regression\", end=': ')\n",
    "print(logit_accuracy)\n",
    "\n",
    "print(\"Accuracy with Decision Tree\", end=': ')\n",
    "print(tree_accuracy)\n",
    "print(\"Accuracy with Decision Tree after Hyper Parameter Tuning: \", end = ':')\n",
    "print(dt_best_param_score)\n",
    "\n",
    "print(\"Accuracy with Random Forest\", end=': ')\n",
    "print(rf_accuracy)\n",
    "if grid_search_enable == True:\n",
    "    print(\"Accuracy with Random Forest after Hyper Parameter Tuning\", end=': ')\n",
    "    print(rf_hyper_accuracy)\n",
    "\n",
    "print(\"Accuracy with Ada Boost\", end=': ')\n",
    "print(ada_boost_accuracy)\n",
    "if grid_search_enable == True:\n",
    "    print(\"Accuracy with Ada Boost after Hyper Parameter Tuning\", end=': ')\n",
    "    print(ada_best_hyper_accuracy)\n",
    "\n",
    "print(\"Accuracy with Gradient Boost\", end=': ')\n",
    "print(gbc_accuracy)\n",
    "if grid_search_enable == True:\n",
    "    print(\"Accuracy with Gradient Boost after Hyper Parameter Tuning\", end=': ')\n",
    "    print(gbc_best_hyper_accuracy)\n",
    "    \n",
    "print(\"Accuracy with LGBM\", end=': ')\n",
    "print(lgbm_accuracy)\n",
    "if grid_search_enable == True:\n",
    "    print(\"Accuracy with LGBM after Hyper Parameter Tuning\", end=': ')\n",
    "    print(LGBM_accuracy_score)\n",
    "    \n",
    "print(\"Accuracy with XG Boost\", end=': ')\n",
    "print(xgb_accuracy)\n",
    "if grid_search_enable == True:\n",
    "    print(\"Accuracy with XG Boost after Hyper Parameter Tuning\", end=': ')\n",
    "    print(xgb_best_hyper_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
